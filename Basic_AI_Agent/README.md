# ğŸ§  Basic AI Agent with Memory and Web UI

A minimal yet powerful AI chatbot built using **Langchain**, **Ollama**, and **Streamlit**. This agent supports persistent memory across conversations and a clean web interface for interaction.

## ğŸš€ Features

- ğŸ¤– **AI-powered Conversations** with [Ollama](https://ollama.com/)
- ğŸ§  **Contextual Memory**: Maintains chat history using Langchain's `ChatMessageHistory`
- ğŸ–¥ï¸ **Interactive Web UI** powered by Streamlit
- ğŸ”„ **Dynamic Prompting**: Uses chat history to enhance AI responses
- ğŸ› ï¸ Easily extensible for other agentic capabilities

## ğŸ“¦ Tech Stack

- [Streamlit](https://streamlit.io/) â€“ Frontend UI for interaction
- [Langchain](https://www.langchain.com/) â€“ Memory management and prompt chaining
- [Ollama](https://ollama.com/) â€“ Lightweight local LLMs like `mistral`, `llama3`, etc.

## ğŸ“‹ How It Works

1. User types a question in the Streamlit web UI.
2. Chat history is retrieved and fed into a prompt template.
3. The model (via Ollama) generates a context-aware response.
4. Both the question and the answer are added to memory.
5. Chat history is displayed in a readable format.

## ğŸ’¡ Example Use Case

Use this as a starter for:
- Smart personal assistants
- Customer support bots
- Teaching or tutoring agents
- Internal productivity tools

## ğŸ“· UI Snapshot
![image](https://github.com/user-attachments/assets/41676941-cb9e-49c7-8dc1-9398e9e10360)

With Memory Releated Query : 
![image](https://github.com/user-attachments/assets/5502bcfd-bb19-490e-ac90-1a7bb4a229a0)


## ğŸ› ï¸ Run the Agent

```bash
# Install dependencies
pip install streamlit langchain langchain-community langchain-core langchain-ollama

# Make sure Ollama is installed and running:
# https://ollama.com/download

# Run the Streamlit app
streamlit run app.py
